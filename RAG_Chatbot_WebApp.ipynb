{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "e741ee24",
        "outputId": "c9ef6666-9846-49d7-91e3-aa02fd6d998d"
      },
      "source": [
        "# RAG-based Chatbot with PDF, CSV, Excel Support\n",
        "# For Google Colab - Free and Open Source Implementation\n",
        "\n",
        "# Install required packages\n",
        "!pip install pinecone-client langchain langchain-community sentence-transformers\n",
        "!pip install PyPDF2 pandas openpyxl faiss-cpu\n",
        "!pip install google-generativeai langchain-google-genai\n",
        "!pip install streamlit gradio\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any, Optional\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# File processing imports\n",
        "import PyPDF2\n",
        "from io import BytesIO\n",
        "import json\n",
        "\n",
        "# Vector database and embeddings\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.schema import Document\n",
        "\n",
        "# LLM imports\n",
        "import google.generativeai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# UI\n",
        "import gradio as gr\n",
        "\n",
        "class MultiFormatRAGChatbot:\n",
        "    def __init__(self, pinecone_api_key: str, gemini_api_key: str):\n",
        "        \"\"\"\n",
        "        Initialize the RAG chatbot with Pinecone and Gemini API keys\n",
        "        \"\"\"\n",
        "        self.pinecone_api_key = pinecone_api_key\n",
        "        self.gemini_api_key = gemini_api_key\n",
        "\n",
        "        # Initialize Pinecone client\n",
        "        self.pc = Pinecone(api_key=pinecone_api_key)\n",
        "\n",
        "        # Your Pinecone index configuration\n",
        "        self.index_name = \"rag-chatbot-csv\"\n",
        "        self.index_host = \"https://rag-chatbot-csv-xp61bOh.svc.aped-4627-b74a.pinecone.io\"\n",
        "\n",
        "        # Initialize embeddings model (matching your Pinecone dimensions: 1024)\n",
        "        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "        # Initialize LLM\n",
        "        genai.configure(api_key=gemini_api_key)\n",
        "        self.llm = ChatGoogleGenerativeAI(\n",
        "            model=\"gemini-2.5-flash\",\n",
        "            google_api_key=gemini_api_key,\n",
        "            temperature=0.3,\n",
        "            convert_system_message_to_human=True\n",
        "        )\n",
        "\n",
        "        # Text splitter for chunking documents\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000,\n",
        "            chunk_overlap=200,\n",
        "            length_function=len\n",
        "        )\n",
        "\n",
        "        # Connect to Pinecone index\n",
        "        self.setup_pinecone_index()\n",
        "\n",
        "        print(\"âœ… RAG Chatbot initialized successfully!\")\n",
        "\n",
        "    def setup_pinecone_index(self):\n",
        "        \"\"\"Setup Pinecone index connection\"\"\"\n",
        "        try:\n",
        "            # Check if index exists\n",
        "            existing_indexes = self.pc.list_indexes()\n",
        "            index_names = [index.name for index in existing_indexes.indexes]\n",
        "\n",
        "            if self.index_name not in index_names:\n",
        "                # Create index if it doesn't exist\n",
        "                self.pc.create_index(\n",
        "                    name=self.index_name,\n",
        "                    dimension=1024,  # Matching your configuration\n",
        "                    metric='cosine',\n",
        "                    spec=ServerlessSpec(\n",
        "                        cloud='aws',\n",
        "                        region='us-east-1'\n",
        "                    )\n",
        "                )\n",
        "                print(f\"âœ… Created new Pinecone index: {self.index_name}\")\n",
        "\n",
        "            self.index = self.pc.Index(self.index_name)\n",
        "            print(f\"âœ… Connected to Pinecone index: {self.index_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error setting up Pinecone index: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def extract_text_from_pdf(self, pdf_file) -> str:\n",
        "        \"\"\"Extract text from PDF file\"\"\"\n",
        "        try:\n",
        "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "            text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error extracting text from PDF: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def process_csv_file(self, csv_file) -> str:\n",
        "        \"\"\"Process CSV file and convert to text\"\"\"\n",
        "        try:\n",
        "            df = pd.read_csv(csv_file)\n",
        "\n",
        "            # Create a comprehensive text representation\n",
        "            text_content = f\"CSV Dataset Summary:\\n\"\n",
        "            text_content += f\"Total rows: {len(df)}\\n\"\n",
        "            text_content += f\"Total columns: {len(df.columns)}\\n\"\n",
        "            text_content += f\"Columns: {', '.join(df.columns)}\\n\\n\"\n",
        "\n",
        "            # Add column information\n",
        "            text_content += \"Column Information:\\n\"\n",
        "            for col in df.columns:\n",
        "                text_content += f\"- {col}: {df[col].dtype}\\n\"\n",
        "\n",
        "            # Add sample data\n",
        "            text_content += f\"\\nSample Data (first 5 rows):\\n\"\n",
        "            text_content += df.head().to_string()\n",
        "\n",
        "            # Add statistical summary for numeric columns\n",
        "            numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "            if len(numeric_cols) > 0:\n",
        "                text_content += f\"\\n\\nStatistical Summary for Numeric Columns:\\n\"\n",
        "                text_content += df[numeric_cols].describe().to_string()\n",
        "\n",
        "            # Add all data in a structured format\n",
        "            text_content += f\"\\n\\nComplete Dataset:\\n\"\n",
        "            for idx, row in df.iterrows():\n",
        "                row_text = f\"Row {idx + 1}: \"\n",
        "                for col in df.columns:\n",
        "                    row_text += f\"{col}: {row[col]}, \"\n",
        "                text_content += row_text.rstrip(\", \") + \"\\n\"\n",
        "\n",
        "            return text_content\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error processing CSV file: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def process_excel_file(self, excel_file) -> str:\n",
        "        \"\"\"Process Excel file and convert to text\"\"\"\n",
        "        try:\n",
        "            # Read all sheets\n",
        "            xls = pd.ExcelFile(excel_file)\n",
        "            text_content = f\"Excel File Summary:\\n\"\n",
        "            text_content += f\"Total sheets: {len(xls.sheet_names)}\\n\"\n",
        "            text_content += f\"Sheet names: {', '.join(xls.sheet_names)}\\n\\n\"\n",
        "\n",
        "            for sheet_name in xls.sheet_names:\n",
        "                df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
        "\n",
        "                text_content += f\"\\n{'='*50}\\n\"\n",
        "                text_content += f\"Sheet: {sheet_name}\\n\"\n",
        "                text_content += f\"{'='*50}\\n\"\n",
        "\n",
        "                # Add sheet summary\n",
        "                text_content += f\"Rows: {len(df)}, Columns: {len(df.columns)}\\n\"\n",
        "                text_content += f\"Columns: {', '.join(df.columns)}\\n\\n\"\n",
        "\n",
        "                # Add sample data\n",
        "                text_content += f\"Sample Data (first 5 rows):\\n\"\n",
        "                text_content += df.head().to_string()\n",
        "\n",
        "                # Add all data\n",
        "                text_content += f\"\\n\\nComplete Data:\\n\"\n",
        "                for idx, row in df.iterrows():\n",
        "                    row_text = f\"Row {idx + 1}: \"\n",
        "                    for col in df.columns:\n",
        "                        row_text += f\"{col}: {row[col]}, \"\n",
        "                    text_content += row_text.rstrip(\", \") + \"\\n\"\n",
        "\n",
        "                text_content += \"\\n\"\n",
        "\n",
        "            return text_content\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error processing Excel file: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def create_embeddings(self, text: str) -> List[float]:\n",
        "        \"\"\"Create embeddings for text using SentenceTransformer\"\"\"\n",
        "        try:\n",
        "            embeddings = self.embedding_model.encode(text)\n",
        "            # Pad or truncate to match Pinecone dimension (1024)\n",
        "            if len(embeddings) < 1024:\n",
        "                embeddings = np.pad(embeddings, (0, 1024 - len(embeddings)), 'constant')\n",
        "            elif len(embeddings) > 1024:\n",
        "                embeddings = embeddings[:1024]\n",
        "\n",
        "            return embeddings.tolist()\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error creating embeddings: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def add_documents_to_index(self, documents: List[Document], file_type: str, filename: str):\n",
        "        \"\"\"Add documents to Pinecone index\"\"\"\n",
        "        try:\n",
        "            vectors = []\n",
        "            for i, doc in enumerate(documents):\n",
        "                embedding = self.create_embeddings(doc.page_content)\n",
        "                if embedding:\n",
        "                    vectors.append({\n",
        "                        'id': f\"{filename}_{file_type}_{i}\",\n",
        "                        'values': embedding,\n",
        "                        'metadata': {\n",
        "                            'text': doc.page_content,\n",
        "                            'file_type': file_type,\n",
        "                            'filename': filename,\n",
        "                            'chunk_id': i\n",
        "                        }\n",
        "                    })\n",
        "\n",
        "            # Upsert vectors to Pinecone\n",
        "            if vectors:\n",
        "                self.index.upsert(vectors=vectors)\n",
        "                print(f\"âœ… Added {len(vectors)} chunks to Pinecone index\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error adding documents to index: {str(e)}\")\n",
        "\n",
        "    def process_and_store_file(self, file_path: str, file_type: str):\n",
        "        \"\"\"Process file and store in vector database\"\"\"\n",
        "        try:\n",
        "            filename = os.path.basename(file_path)\n",
        "\n",
        "            # Extract text based on file type\n",
        "            if file_type == 'pdf':\n",
        "                text = self.extract_text_from_pdf(file_path)\n",
        "            elif file_type == 'csv':\n",
        "                text = self.process_csv_file(file_path)\n",
        "            elif file_type in ['xlsx', 'xls']:\n",
        "                text = self.process_excel_file(file_path)\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported file type: {file_type}\")\n",
        "\n",
        "            if not text:\n",
        "                return f\"âŒ Failed to extract text from {filename}\"\n",
        "\n",
        "            # Split text into chunks\n",
        "            documents = self.text_splitter.create_documents([text])\n",
        "\n",
        "            # Add to vector database\n",
        "            self.add_documents_to_index(documents, file_type, filename)\n",
        "\n",
        "            return f\"âœ… Successfully processed and stored {filename} ({len(documents)} chunks)\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"âŒ Error processing file: {str(e)}\"\n",
        "\n",
        "    def search_similar_documents(self, query: str, top_k: int = 5) -> List[Dict]:\n",
        "        \"\"\"Search for similar documents in Pinecone\"\"\"\n",
        "        try:\n",
        "            # Create query embedding\n",
        "            query_embedding = self.create_embeddings(query)\n",
        "\n",
        "            # Search in Pinecone\n",
        "            search_results = self.index.query(\n",
        "                vector=query_embedding,\n",
        "                top_k=top_k,\n",
        "                include_metadata=True\n",
        "            )\n",
        "\n",
        "            # Format results\n",
        "            results = []\n",
        "            for match in search_results['matches']:\n",
        "                results.append({\n",
        "                    'text': match['metadata']['text'],\n",
        "                    'score': match['score'],\n",
        "                    'file_type': match['metadata']['file_type'],\n",
        "                    'filename': match['metadata']['filename']\n",
        "                })\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error searching documents: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    def generate_response(self, query: str, context_docs: List[Dict]) -> str:\n",
        "        \"\"\"Generate response using Gemini with context\"\"\"\n",
        "        try:\n",
        "            # Prepare context\n",
        "            context = \"\\n\\n\".join([doc['text'] for doc in context_docs])\n",
        "\n",
        "            # Create prompt\n",
        "            prompt = f\"\"\"\n",
        "            You are a helpful AI assistant that answers questions based on the provided context from uploaded documents.\n",
        "\n",
        "            Context from documents:\n",
        "            {context}\n",
        "\n",
        "            User Question: {query}\n",
        "\n",
        "            Instructions:\n",
        "            1. Answer the question based on the provided context\n",
        "            2. If the context doesn't contain enough information, say so\n",
        "            3. Be specific and cite relevant information from the context\n",
        "            4. If working with CSV/Excel data, provide specific data points when relevant\n",
        "\n",
        "            Answer:\n",
        "            \"\"\"\n",
        "\n",
        "            # Generate response\n",
        "            response = self.llm.predict(prompt)\n",
        "            return response\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"âŒ Error generating response: {str(e)}\"\n",
        "\n",
        "    def chat(self, query: str) -> str:\n",
        "        \"\"\"Main chat function\"\"\"\n",
        "        try:\n",
        "            # Search for relevant documents\n",
        "            relevant_docs = self.search_similar_documents(query, top_k=5)\n",
        "\n",
        "            if not relevant_docs:\n",
        "                return \"âŒ No relevant documents found. Please upload some files first.\"\n",
        "\n",
        "            # Generate response\n",
        "            response = self.generate_response(query, relevant_docs)\n",
        "\n",
        "            # Add source information\n",
        "            sources = list(set([doc['filename'] for doc in relevant_docs]))\n",
        "            response += f\"\\n\\nðŸ“„ Sources: {', '.join(sources)}\"\n",
        "\n",
        "            return response\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"âŒ Error in chat: {str(e)}\"\n",
        "\n",
        "# Gradio Interface\n",
        "def create_gradio_interface():\n",
        "    \"\"\"Create Gradio interface for the chatbot\"\"\"\n",
        "\n",
        "    # Initialize chatbot (you'll need to provide your API keys)\n",
        "    chatbot = None\n",
        "\n",
        "    def initialize_chatbot(pinecone_key, gemini_key):\n",
        "        global chatbot\n",
        "        try:\n",
        "            chatbot = MultiFormatRAGChatbot(pinecone_key, gemini_key)\n",
        "            return \"âœ… Chatbot initialized successfully!\"\n",
        "        except Exception as e:\n",
        "            return f\"âŒ Error initializing chatbot: {str(e)}\"\n",
        "\n",
        "    def upload_and_process_file(file):\n",
        "        global chatbot\n",
        "        if chatbot is None:\n",
        "            return \"âŒ Please initialize the chatbot first with your API keys.\"\n",
        "\n",
        "        if file is None:\n",
        "            return \"âŒ Please upload a file.\"\n",
        "\n",
        "        try:\n",
        "            # Determine file type\n",
        "            filename = file.name\n",
        "            if filename.endswith('.pdf'):\n",
        "                file_type = 'pdf'\n",
        "            elif filename.endswith('.csv'):\n",
        "                file_type = 'csv'\n",
        "            elif filename.endswith(('.xlsx', '.xls')):\n",
        "                file_type = 'xlsx'\n",
        "            else:\n",
        "                return \"âŒ Unsupported file type. Please upload PDF, CSV, or Excel files.\"\n",
        "\n",
        "            # Process file\n",
        "            result = chatbot.process_and_store_file(file.name, file_type)\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"âŒ Error processing file: {str(e)}\"\n",
        "\n",
        "    def chat_with_bot(message, history):\n",
        "        global chatbot\n",
        "        if chatbot is None:\n",
        "            return \"âŒ Please initialize the chatbot first with your API keys.\"\n",
        "\n",
        "        response = chatbot.chat(message)\n",
        "        return response\n",
        "\n",
        "    # Create Gradio interface\n",
        "    with gr.Blocks(title=\"RAG Chatbot - Multi-Format File Support\") as demo:\n",
        "        gr.Markdown(\"# ðŸ¤– RAG Chatbot with PDF, CSV, Excel Support\")\n",
        "        gr.Markdown(\"Upload your documents and chat with them using AI!\")\n",
        "\n",
        "        with gr.Tab(\"Setup\"):\n",
        "            gr.Markdown(\"## ðŸ”§ Initialize Chatbot\")\n",
        "            with gr.Row():\n",
        "                pinecone_key = gr.Textbox(\n",
        "                    label=\"Pinecone API Key\",\n",
        "                    type=\"password\",\n",
        "                    placeholder=\"Enter your Pinecone API key\"\n",
        "                )\n",
        "                gemini_key = gr.Textbox(\n",
        "                    label=\"Google Gemini API Key\",\n",
        "                    type=\"password\",\n",
        "                    placeholder=\"Enter your Google Gemini API key\"\n",
        "                )\n",
        "\n",
        "            init_btn = gr.Button(\"Initialize Chatbot\", variant=\"primary\")\n",
        "            init_output = gr.Textbox(label=\"Initialization Status\", interactive=False)\n",
        "\n",
        "            init_btn.click(\n",
        "                initialize_chatbot,\n",
        "                inputs=[pinecone_key, gemini_key],\n",
        "                outputs=init_output\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"Upload Files\"):\n",
        "            gr.Markdown(\"## ðŸ“ Upload Documents\")\n",
        "            file_upload = gr.File(\n",
        "                label=\"Upload PDF, CSV, or Excel files\",\n",
        "                file_types=[\".pdf\", \".csv\", \".xlsx\", \".xls\"]\n",
        "            )\n",
        "            upload_btn = gr.Button(\"Process File\", variant=\"primary\")\n",
        "            upload_output = gr.Textbox(label=\"Processing Status\", interactive=False)\n",
        "\n",
        "            upload_btn.click(\n",
        "                upload_and_process_file,\n",
        "                inputs=file_upload,\n",
        "                outputs=upload_output\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"Chat\"):\n",
        "            gr.Markdown(\"## ðŸ’¬ Chat with Your Documents\")\n",
        "            chatbot_interface = gr.Chatbot(height=400)\n",
        "            msg = gr.Textbox(\n",
        "                label=\"Your Message\",\n",
        "                placeholder=\"Ask questions about your uploaded documents...\"\n",
        "            )\n",
        "\n",
        "            def respond(message, chat_history):\n",
        "                bot_message = chat_with_bot(message, chat_history)\n",
        "                chat_history.append((message, bot_message))\n",
        "                return \"\", chat_history\n",
        "\n",
        "            msg.submit(respond, [msg, chatbot_interface], [msg, chatbot_interface])\n",
        "\n",
        "            gr.Examples(\n",
        "                examples=[\n",
        "                    \"What is the main topic of the uploaded document?\",\n",
        "                    \"Can you summarize the key findings?\",\n",
        "                    \"What data is available in the CSV file?\",\n",
        "                    \"Show me the statistics from the Excel sheet\",\n",
        "                    \"What are the column names in the dataset?\"\n",
        "                ],\n",
        "                inputs=msg\n",
        "            )\n",
        "\n",
        "    return demo\n",
        "\n",
        "# Usage Instructions\n",
        "print(\"\"\"\n",
        "ðŸš€ RAG Chatbot Setup Instructions:\n",
        "\n",
        "1. **Get API Keys:**\n",
        "   - Pinecone: https://www.pinecone.io/ (Free tier available)\n",
        "   - Google Gemini: https://ai.google.dev/ (Free tier available)\n",
        "\n",
        "2. **Run the Gradio Interface:**\n",
        "   ```python\n",
        "   demo = create_gradio_interface()\n",
        "   demo.launch(share=True, debug=True)\n",
        "   ```\n",
        "\n",
        "3. **Initialize the chatbot with your API keys**\n",
        "\n",
        "4. **Upload your PDF, CSV, or Excel files**\n",
        "\n",
        "5. **Start chatting with your documents!**\n",
        "\n",
        "ðŸ“ Features:\n",
        "- âœ… PDF text extraction\n",
        "- âœ… CSV data analysis\n",
        "- âœ… Excel multi-sheet support\n",
        "- âœ… Vector similarity search\n",
        "- âœ… Context-aware responses\n",
        "- âœ… Source attribution\n",
        "- âœ… Free and open-source\n",
        "\"\"\")\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    demo = create_gradio_interface()\n",
        "    demo.launch(share=True, debug=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.11/dist-packages (6.0.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2025.6.15)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.14.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2.4.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.68)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.3.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.0.10)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.175.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.37 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.68)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (0.4.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.6.15)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.37->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.46.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.3.1)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.14)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.2)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.45.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "\n",
            "ðŸš€ RAG Chatbot Setup Instructions:\n",
            "\n",
            "1. **Get API Keys:**\n",
            "   - Pinecone: https://www.pinecone.io/ (Free tier available)\n",
            "   - Google Gemini: https://ai.google.dev/ (Free tier available)\n",
            "\n",
            "2. **Run the Gradio Interface:**\n",
            "   ```python\n",
            "   demo = create_gradio_interface()\n",
            "   demo.launch(share=True, debug=True)\n",
            "   ```\n",
            "\n",
            "3. **Initialize the chatbot with your API keys**\n",
            "\n",
            "4. **Upload your PDF, CSV, or Excel files**\n",
            "\n",
            "5. **Start chatting with your documents!**\n",
            "\n",
            "ðŸ“ Features:\n",
            "- âœ… PDF text extraction\n",
            "- âœ… CSV data analysis\n",
            "- âœ… Excel multi-sheet support\n",
            "- âœ… Vector similarity search\n",
            "- âœ… Context-aware responses\n",
            "- âœ… Source attribution\n",
            "- âœ… Free and open-source\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://1d049385c582ab59e0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1d049385c582ab59e0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Connected to Pinecone index: rag-chatbot-csv\n",
            "âœ… RAG Chatbot initialized successfully!\n",
            "âœ… Added 96 chunks to Pinecone index\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://1d049385c582ab59e0.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bA8SYNb29Qis"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}